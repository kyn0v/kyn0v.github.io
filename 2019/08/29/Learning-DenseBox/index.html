<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>DenseBox代码解析 | Kyno&#39;s Blog🐱‍🏍</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="距离上次更新博客又很久了。前段时间照着github上的代码复现了下DenseBox，有所收获记录一下。   DenseBox代码整体结构 densebox&#x2F;   __init__.py：将文件夹变为一个Python模块   DenseBox.py：网络结构相关代码   DenseBoxDataset.py：数据集加载相关代码     train.py：构建网络-&gt;读取数据-&gt;训练网络">
<meta property="og:type" content="article">
<meta property="og:title" content="DenseBox代码解析">
<meta property="og:url" content="http://example.com/2019/08/29/Learning-DenseBox/index.html">
<meta property="og:site_name" content="Kyno&#39;s Blog🐱‍🏍">
<meta property="og:description" content="距离上次更新博客又很久了。前段时间照着github上的代码复现了下DenseBox，有所收获记录一下。   DenseBox代码整体结构 densebox&#x2F;   __init__.py：将文件夹变为一个Python模块   DenseBox.py：网络结构相关代码   DenseBoxDataset.py：数据集加载相关代码     train.py：构建网络-&gt;读取数据-&gt;训练网络">
<meta property="og:locale">
<meta property="article:published_time" content="2019-08-29T13:08:39.000Z">
<meta property="article:modified_time" content="2021-02-06T15:04:56.760Z">
<meta property="article:author" content="Kyno Yang">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Kyno's Blog🐱‍🏍" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Kyno&#39;s Blog🐱‍🏍</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">棉纺厂原住民，东纺幼儿园毕业生</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Suche"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Suche"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-Learning-DenseBox" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2019/08/29/Learning-DenseBox/" class="article-date">
  <time class="dt-published" datetime="2019-08-29T13:08:39.000Z" itemprop="datePublished">2019-08-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      DenseBox代码解析
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>距离上次更新博客又很久了。前段时间照着github上的代码复现了下DenseBox，有所收获记录一下。  </p>
<h1 id="DenseBox代码整体结构"><a href="#DenseBox代码整体结构" class="headerlink" title="DenseBox代码整体结构"></a>DenseBox代码整体结构</h1><ul>
<li>densebox/  <ul>
<li>__init__.py：将文件夹变为一个Python模块  </li>
<li>DenseBox.py：网络结构相关代码  </li>
<li>DenseBoxDataset.py：数据集加载相关代码  </li>
</ul>
</li>
<li>train.py：构建网络-&gt;读取数据-&gt;训练网络  </li>
<li>test.py：构建网络-&gt;读取数据-&gt;测试数据  </li>
</ul>
<h2 id="densebox-init-py解析"><a href="#densebox-init-py解析" class="headerlink" title="densebox/__init__.py解析"></a>densebox/__init__.py解析</h2><p>densebox文件夹下，__init__文件的内容为:  </p>
<pre><code>from .DenseBoxDataset import DenseBoxDataset  
from .DenseBox import DenseBox  
__all__ = [&#39;DenseBoxDataset&#39;, &#39;DenseBox&#39;]  
</code></pre>
<p>这段代码的作用是使得densebox文件夹变为一个模块，换一个角度来说，就是提升了包的导入权限，只要在__all__中声明的内容，可以直接在上一层目录中导入，如train.py文件的开头：  </p>
<pre><code>from densebox import DenseBoxDataset  
from densebox import DenseBox  
</code></pre>
<p>如果使用<code>from densebox import *</code>，则会把注册在__all__列表中的子模块和子包导入到当前作用域中来。  </p>
<h2 id="densebox-DenseBox-py解析"><a href="#densebox-DenseBox-py解析" class="headerlink" title="densebox/DenseBox.py解析"></a>densebox/DenseBox.py解析</h2><p>DenseBox.py用于构建网络结构，首先定义模型结构<code>class DenseBox(torch.nn.Module)</code>，然后实现<code>__init__</code>函数和<code>forward</code>函数。  </p>
<ul>
<li><p>__init__(self, vgg19)  </p>
<p>  __init__函数用于初始化网络结构，它继承父类的__init__函数：<code>super(DenseBox, self).__init__()</code>  </p>
<p>  参数vgg19用于初始化DenseBox初始结构，因为DenseBox的主干网络是基于vgg19的：<code>feats = vgg19.features._modules</code>  </p>
<p>  然后依次添加卷积、池化等网络结构：  </p>
<pre><code># ----------------- Conv1  
self.conv1_1_1 = copy.deepcopy(feats[&#39;0&#39;])  # (0)  
self.conv1_1_2 = copy.deepcopy(feats[&#39;1&#39;])  # (1)  
self.conv1_1 = nn.Sequential(  
    self.conv1_1_1,  
    self.conv1_1_2  
)  # conv_layer1  

#...(中间结构省略)...  

# ----------------- Conv4  
self.conv4_1_1 = copy.deepcopy(feats[&#39;19&#39;])  # (19)  
self.conv4_1_2 = copy.deepcopy(feats[&#39;20&#39;])  # (20)  
self.conv4_1 = nn.Sequential(  
    self.conv4_1_1,  
    self.conv4_1_2  
)  # conv_layer9  

self.conv4_2_1 = copy.deepcopy(feats[&#39;21&#39;])  # (21)  
self.conv4_2_2 = copy.deepcopy(feats[&#39;22&#39;])  # (22)  
self.conv4_2 = nn.Sequential(  
    self.conv4_2_1,  
    self.conv4_2_2  
)  # conv_layer10  

self.conv4_3_1 = copy.deepcopy(feats[&#39;23&#39;])  # (23)  
self.conv4_3_2 = copy.deepcopy(feats[&#39;24&#39;])  # (24)  
self.conv4_3 = nn.Sequential(  
    self.conv4_3_1,  
    self.conv4_3_2  
)  # conv_layer11  

self.conv4_4_1 = copy.deepcopy(feats[&#39;25&#39;])  # (25)  
self.conv4_4_2 = copy.deepcopy(feats[&#39;26&#39;])  # (26)  
self.conv4_4 = nn.Sequential(  
    self.conv4_4_1,  
    self.conv4_4_2  
)  
</code></pre>
<p>  score output结构，输出置信分：  </p>
<pre><code>self.conv5_1_det = nn.Conv2d(in_channels=768,  
                                 out_channels=512,  
                                 kernel_size=(1, 1))  
self.conv5_2_det = nn.Conv2d(in_channels=512,  
                                out_channels=1,  
                                kernel_size=(1, 1))  
torch.nn.init.xavier_normal_(self.conv5_1_det.weight.data)  
torch.nn.init.xavier_normal_(self.conv5_2_det.weight.data)  

self.output_score = nn.Sequential(  
    self.conv5_1_det,  
    nn.Dropout(),  
    self.conv5_2_det  
)  
</code></pre>
<p>  loc output结构，输出bbox偏移量：  </p>
<pre><code>self.conv5_1_loc = nn.Conv2d(in_channels=768,  
                                 out_channels=512,  
                                 kernel_size=(1, 1))  
self.conv5_2_loc = nn.Conv2d(in_channels=512,  
                                out_channels=4,  
                                kernel_size=(1, 1))  
torch.nn.init.xavier_normal_(self.conv5_1_loc.weight.data)  
torch.nn.init.xavier_normal_(self.conv5_2_loc.weight.data)  

self.output_loc = nn.Sequential(  
    self.conv5_1_loc,  
    nn.Dropout(),  
    self.conv5_2_loc  
)  
</code></pre>
</li>
<li><p>forward(self, X)  </p>
<p>  forward函数用于前向传播，输入为图像X，依次通过网络各个结构：  </p>
<pre><code>X = self.conv1_1(X)  
X = self.conv1_2(X)  
X = self.pool1(X)  
#...(省略中间过程)...  
conv4_4_X = self.conv4_4(X)  

# 上采样后与低层特征进行特征融合  
conv4_4_X_us = nn.Upsample(size=(conv3_4_X.size(2),  
                                     conv3_4_X.size(3)),  
                            mode=&#39;bilinear&#39;,  
                            align_corners=True)(conv4_4_X)  
fusion = torch.cat((conv4_4_X_us, conv3_4_X), dim=1)  

#返回结果  
scores = self.output_score(fusion)  
locs = self.output_loc(fusion)  
return scores, locs  
</code></pre>
</li>
</ul>
<h2 id="densebox-DenseBoxDataset-py解析"><a href="#densebox-DenseBoxDataset-py解析" class="headerlink" title="densebox/DenseBoxDataset.py解析"></a>densebox/DenseBoxDataset.py解析</h2><p>DenseBoxDataset.py用于处理读入数据，首先定义自定义数据集<code>class DenseBoxDataset(Dataset)</code>，然后主要实现<code>__init__</code>函数、<code>__getitem__</code>函数和<code>__len__</code>函数。  </p>
<ul>
<li><p>__init__(self, root, ann_file = ‘train.json’, size=(240, 240), test_mode=False)  </p>
<p>  __init__函数用于初始化输入数据（所有图片的annotation），并将其转换到要求的形式读入内存：  </p>
<ol>
<li>首先加载数据集所有图片信息（load_annotations函数）；  </li>
<li>然后从读取的数据中解析出每张图片的annotation信息（get_ann_info函数和_parse_ann_info函数），从annotation中解析出bbox信息和label信息（如果需要，还可以bbox转换到指定的坐标空间），并使用list有序保存。这样每张图片的GT就加载到内存中了；  </li>
<li>最后设置用于“格式化”图片的transform函数。  </li>
</ol>
</li>
<li><p>__getitem__(self, idx)<br>  __getitem__函数，在test阶段只返回图片，在train阶段返回图片以及对应GT。目前我只实现了train阶段的部分：  </p>
<ol>
<li>从__init__中已经初始化的所有图片信息中获得指定idx的图片名，并读取该图片，然后使用__init__中的“格式化”手段变换图片；  </li>
<li>从__init__中已经解析好的bbox信息和label信息中，取得指定idx对应的数据。  </li>
<li>返回图片+GT数据（annotation中解析出的内容）。这里使用的数据集中不含有负样本（没有目标的样本图片）。  </li>
</ol>
</li>
<li><p>__len__(self)<br>  __len__函数返回数据集的大小（图片数量）：<br>  返回__init__中存储所有图片信息的list的长度即可。  </p>
</li>
<li><p>show(img, bboxes):<br>  为了可视化数据加载的是否成功，我编写一个全局函数：  </p>
<pre><code>def show(img, bboxes):  
    &quot;&quot;&quot;  
    img为tensor格式，bbox为list  
    &quot;&quot;&quot;  
    img = np.array(img)  
    img = np.transpose(img,(1,2,0))  
    plt.imshow(img)  
    #画矩形框  
    for bbox in bboxes:  
        xmin = bbox[0]  
        ymin = bbox[1]  
        xmax = bbox[2]  
        ymax = bbox[3]  
        top = ([xmin, xmax], [ymin, ymin])  
        right = ([xmax, xmax], [ymin, ymax])  
        botton = ([xmax, xmin], [ymax, ymax])  
        left = ([xmin, xmin], [ymax, ymin])  
        lines = [top, right, botton, left]  
        for line in lines:  
            plt.plot(*line, color = &#39;r&#39;)  
            plt.scatter(*line, color = &#39;b&#39;)  
    #调整原点到左上角  
    ax = plt.gca()  
    ax.xaxis.set_ticks_position(&#39;top&#39;)  
    plt.show()  
</code></pre>
</li>
</ul>
<h2 id="train-py解析"><a href="#train-py解析" class="headerlink" title="train.py解析"></a>train.py解析</h2><p>train.py即模型的训练过程，包含采样策略。常规训练流程：加载数据集 -&gt; 设置train_loader -&gt; 网络初始化 -&gt; 设置损失函数 -&gt; 设置优化策略 -&gt; 调整网络为训练模式 -&gt; 训练循环。以下列举重点进行分析：  </p>
<ul>
<li><p>train_loader：首先根据batchsize的数值决定调用DenseBoxDataset的<code>__getitem__</code>函数的次数；然后通过<code>collate_fn</code>函数对读取到的batch进一步加工：将读取到的一个batch中的多组数据整合，即增加一个batch维度；最后将batchsize个的batch合并。  </p>
<pre><code>def collate_fn_customer(batch):  
images = []  
bboxes = []  
for i, data in enumerate(batch):  
    # data[0]为img维度  
    images.append(data[0])  
    # data[1]为bbox维度  
    bboxes.append(data[1])  
#对images进行类型转换:list-&gt;torch.tensor  
#注意一张图片中可能有多个bbox，bbox维度不同使用`stack`函数会报错,因此直接返回list形式的bboxes  
images = torch.stack(images)  
batch = (images, bboxes)  
return batch  
</code></pre>
</li>
<li><p>定义网络、损失函数、优化策略，网络和数据需要加载到GPU上，之后设置网络为训练模式：  </p>
<pre><code>os.environ[&#39;CUDA_DEVICE_ORDER&#39;] = &#39;PCI_BUS_ID&#39;  
os.environ[&#39;CUDA_VISIBLE_DEVICES&#39;] = &#39;1&#39;  
device = torch.device(&#39;cuda: 0&#39; if torch.cuda.is_available() else &#39;cpu&#39;)  

net = DenseBox(vgg19=vgg19_pretrain).to(device)  
loss_func = nn.MSELoss(reduce=False).to(device)  
optimizer = torch.optim.SGD(net.parameters(),  
                        lr=base_lr,  
                        momentum=9e-1,  
                        weight_decay=5e-8)  # 5e-4 or 5e-8  

net.train()  
</code></pre>
</li>
<li><p>网络训练过程：从dataloader中以batchsize为单位读取数据，batch中分成两部分：img和GT，img作为网络输入，GT转换成指定形式后，参与后续损失的计算：  </p>
<ol>
<li><p>读取batch[0]存储的imgs数据并加载到GPU上  </p>
</li>
<li><p>读取batch[1]存储的bboxes数据：将bboxes数据转换到与输出特征图尺寸对应的score_map、dist_map上，用于损失计算；将bboxes数据转换到mask_map上，用于应用采样策略。然后将它们加载到GPU上。  </p>
</li>
<li><p>清空梯度-&gt;前向传播-&gt;计算分类和定位损失  </p>
</li>
<li><p>采样策略（以batch_size为单位进行采样，而不是一张图为单位）：  </p>
<pre><code># 统计正样本数量  
pos_indices = torch.nonzero(cls_maps_gt)  
positive_num = pos_indices.size(0)  
# 负样本与正样本相等:img.size(0)即batch_size,若这里使用batch_size会在最后不足一个完整batch时报错  
neg_num = int(float(positive_num) / float(img.size(0)) + 0.5)  
# 获得负样本的mask掩码，用于采负样本  
ones_mask = torch.ones([img.size(0), 1, 60, 60],  
                        dtype=torch.float32).to(device)  
neg_mask = ones_mask - cls_maps_gt  
neg_cls_loss = cls_loss * neg_mask  
# 一半从困难负样本获得,一半随机采样  
half_neg_num = int(neg_num * 0.5 + 0.5)  
neg_cls_loss = neg_cls_loss.view(img.size(0), -1)  
hard_negs, hard_neg_indices = torch.topk(input=neg_cls_loss,  
                                            k=half_neg_num,  
                                            dim=1)  
# 随机采样可改进为从负样本中采样,目前是从全体样本中随机采样  
rand_neg_indices = torch.zeros([img.size(0), half_neg_num], dtype=torch.long).to(device)  
for i in range(img.size(0)):  
    indices = np.random.choice(3600, #60*60  
                                half_neg_num,  
                                replace=False)  
    indices = torch.Tensor(indices)  
    rand_neg_indices[i] = indices  
#汇总负样本indices  
neg_indices = torch.cat((hard_neg_indices,  
                            rand_neg_indices),  
                        dim=1)  
neg_indices = neg_indices.cpu()  
pos_indices = pos_indices.cpu()  
</code></pre>
<p> 这样正负样本点就确定了。  </p>
</li>
<li><p>将上述一维空间的样本idx转换到(batchsize, 1, w, h)坐标空间中，更新mask_map；然后通过grayzone去除掉bbox边缘的一部分正样本，更新mask_map;最终确定全部采样点。  </p>
</li>
<li><p>最后将mask_map与损失map相点乘，即可得到最终的损失：  </p>
<pre><code>mask_cls_loss = mask_maps * cls_loss    #分类损失  
mask_bbox_loc_loss = mask_maps * cls_maps_gt * bbox_loc_loss    #定位损失  
full_loss = lambda_cls * (torch.sum(mask_cls_loss)  
            + lambda_loc * torch.sum(mask_bbox_loc_loss))  
</code></pre>
</li>
<li><p>反向传播和更新参数：  </p>
<pre><code>full_loss.backward()  
optimizer.step()  
</code></pre>
</li>
<li><p>log信息的输出与保存、log信息的输出与保存、checkpoint的保存（不同频率）。另外学习率可以随着epoch的增加作相应调整：  </p>
<pre><code>def adjust_LR(optimizer, epoch):  
    lr = 1e-9  
    if epoch &lt; 5:  
        lr = 1e-9  
    elif epoch &gt;= 5 and epoch &lt; 10:  
        lr = 2e-9  
    elif epoch &gt;= 10 and epoch &lt; 15:  
        lr = 4e-9  
    else:  
        lr = 1e-9  
    for param_group in optimizer.param_groups:  
        param_group[&#39;lr&#39;] = lr    #更新lr  

    return lr  
</code></pre>
</li>
</ol>
</li>
</ul>
<h2 id="test-py解析"><a href="#test-py解析" class="headerlink" title="test.py解析"></a>test.py解析</h2><p>test.py即模型测试过程：<br>初始化网络并加载到GPU-&gt;网络切换到测试模式-&gt;读取测试图片并做相应变换-&gt;数据输入网络得到输出-&gt;解析输出并可视化（目前未实现统计评估的功能）。以下列举重点并分析：  </p>
<ul>
<li>初始化网络：首先加载vgg19预训练模型，然后使用vgg19初始化DenseBox网络，最后将保存的检查点加载到DenseBox网络。  <pre><code>vgg19_pretrain = torchvision.models.vgg19()  
vgg19_pretrain.load_state_dict(torch.load(&#39;vgg19.pth&#39;))  
net = DenseBox(vgg19=vgg19_pretrain).to(device)  
net.load_state_dict(torch.load(resume))  
print(&#39;=&gt; 网络从 &#123;&#125; 加载&#39;.format(resume))  
</code></pre>
</li>
<li>使用visdom观察预测结果置信度热图：  <pre><code>import visdom  
vis = visdom.Visdom()  
vis.heatmap(score_out[0,0])  
</code></pre>
</li>
<li>解析输出后使用非极大抑制算法，最后训练阶段编写的<code>show</code>函数可视化结果：  <pre><code>#保留置信度前K的结果，并且解析成bbox形式返回  
dets = parse_out_MN(score_map=score_out.cpu(),  
                            loc_map=loc_out.cpu(),  
                            M=H,  
                            N=W,  
                            K=10)  
# 非极大抑制  
keep = NMS(dets=dets, nms_thresh=0.4)  
dets = dets[keep]  
# 可视化结果(GT+DT)  
show(img_tensor, [[60,101,181,143]])  
show(img_tensor, dets)  
</code></pre>
</li>
</ul>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>这次复现的本质是从头到尾细致地读了一遍代码。收获最大的地方是对数据采样这个方面，有了细致的了解。<br>网络和代码目前可以改进的地方很多：  </p>
<ol>
<li>不支持多尺度，可以结合FPN做改进  </li>
<li>数据加载耗时长，可以考虑多个batch_size的数据批量加载到内存  </li>
<li>测试时的dataloader未完成  </li>
<li>evaluate功能未实现  </li>
<li>细节处可以改进<br>DenseBox代码复现告一段落，之后有时间可能会优化代码。接下来更多着重在mmdetection toolbox上，它的整个框架结构更加成熟，并且也更加高效，值得深入研究。  </li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2019/08/29/Learning-DenseBox/" data-id="ckktumz8l0000zttmgl8jc624" data-title="DenseBox代码解析" class="article-share-link">Teilen</a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2021/02/05/Writing-Blog-in-GitPage/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Neuer</strong>
      <div class="article-nav-title">
        
          Blog in GitPage
        
      </div>
    </a>
  
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archiv</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/02/">February 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">letzter Beitrag</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/02/05/Writing-Blog-in-GitPage/">Blog in GitPage</a>
          </li>
        
          <li>
            <a href="/2019/08/29/Learning-DenseBox/">DenseBox代码解析</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2021 Kyno Yang<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>